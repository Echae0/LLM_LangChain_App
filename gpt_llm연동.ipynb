{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ead71a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain ChatGPT\n"
     ]
    }
   ],
   "source": [
    "print('Hello LangChain ChatGPT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5f628d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "#print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a61086c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 개발자입니다.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "prompt_text = prompt.format(input=\"LangServe은 무엇인가요? 자세하게 설명해주세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b49884c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x0000013F28267080> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000013F2832B3E0> root_client=<openai.OpenAI object at 0x0000013F27EEF2F0> root_async_client=<openai.AsyncOpenAI object at 0x0000013F27E37B00> model_name='gpt-4o' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "# ChatGPT API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    #model_name=\"gpt-3.5-turbo-0125\",\n",
    "    #model_name=\"gpt-4o-mini\",\n",
    "    model_name = \"gpt-4o\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53cd1e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='LangServe은 자연어 처리(NLP)와 관련된 서비스나 플랫폼을 지칭할 가능성이 있습니다. 그러나 \"LangServe\"라는 특정 용어에 대한 정보가 제한적이기 때문에, 이 용어가 특정 회사, 제품 또는 오픈 소스 프로젝트를 의미할 수 있습니다. 일반적으로, 이름에서 유추할 수 있는 정보는 다음과 같습니다.\\n\\n1. **언어 관련 서비스**: \"Lang\"은 \"Language(언어)\"의 약어일 가능성이 높습니다. 따라서 LangServe은 언어 처리와 관련된 서비스를 제공할 가능성이 큽니다.\\n\\n2. **서버 기반**: \"Serve\"는 서버 또는 서비스를 의미할 수 있습니다. 이는 클라이언트-서버 모델을 통해 언어 처리 기능을 제공하는 플랫폼일 수 있음을 암시합니다.\\n\\n3. **자연어 처리(NLP)**: 만약 LangServe이 NLP와 관련이 있다면, 이는 텍스트 분석, 번역, 음성 인식, 챗봇과 같은 다양한 언어 처리 기능을 제공할 수 있습니다.\\n\\n이러한 일반적인 해석 외에, 특정한 기능이나 서비스에 대한 더 구체적인 정보가 필요하다면, 관련 웹사이트나 문서를 참조하거나 추가적인 세부사항을 제공해 주시면 보다 정확한 답변을 드릴 수 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 282, 'prompt_tokens': 28, 'total_tokens': 310, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-BgpTkactkAFVj5IRokW9qamdr12TJ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--acab27d2-18c2-47f6-b7d1-6c5ec1d2642a-0' usage_metadata={'input_tokens': 28, 'output_tokens': 282, 'total_tokens': 310, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "응답: LangServe은 자연어 처리(NLP)와 관련된 서비스나 플랫폼을 지칭할 가능성이 있습니다. 그러나 \"LangServe\"라는 특정 용어에 대한 정보가 제한적이기 때문에, 이 용어가 특정 회사, 제품 또는 오픈 소스 프로젝트를 의미할 수 있습니다. 일반적으로, 이름에서 유추할 수 있는 정보는 다음과 같습니다.\n",
      "\n",
      "1. **언어 관련 서비스**: \"Lang\"은 \"Language(언어)\"의 약어일 가능성이 높습니다. 따라서 LangServe은 언어 처리와 관련된 서비스를 제공할 가능성이 큽니다.\n",
      "\n",
      "2. **서버 기반**: \"Serve\"는 서버 또는 서비스를 의미할 수 있습니다. 이는 클라이언트-서버 모델을 통해 언어 처리 기능을 제공하는 플랫폼일 수 있음을 암시합니다.\n",
      "\n",
      "3. **자연어 처리(NLP)**: 만약 LangServe이 NLP와 관련이 있다면, 이는 텍스트 분석, 번역, 음성 인식, 챗봇과 같은 다양한 언어 처리 기능을 제공할 수 있습니다.\n",
      "\n",
      "이러한 일반적인 해석 외에, 특정한 기능이나 서비스에 대한 더 구체적인 정보가 필요하다면, 관련 웹사이트나 문서를 참조하거나 추가적인 세부사항을 제공해 주시면 보다 정확한 답변을 드릴 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(type(response))\n",
    "    print(response)\n",
    "    print(\"응답:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
